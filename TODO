TODO:

- Make music beats match with a certain frame in a video loop
    - Possible only on tracks with pre-recorded beat locations
    - Required changes:
        - Track tempo database should also have beat positions
            - Add this to the data sent by Rhythmextractor and save in DB
        - Get track change signal from music player with reliable latency
            - Using libdbus directly may help, since dbus-monitor gets signals with semi-reliable latency
            - Spotify emits a few (6 usually) signals when the track changes. Using data from `dbus-monitor "type='signal',sender='org.mpris.MediaPlayer2.spotify'" --profile`
            it can be calculated that timing difference between the last of these 6 signals and the first when song changes
            deviates only ~0.1sec from spotify's reported song length. Needs some more testing though.
        - Update tempo to OpenGLWidget for each loop
            - Use timestamps from song change and inside the widget to match beats
- Improve OpenGLWidget
    - Currently the widget renders textures on a surface which covers the widget/screen
    - Create test implementation where rendering textures on 3D model
    - Add mode where there's only 1 picture but zoom it in/out along with music tempo
        - Should be easy-ish with shaders
- Improve song info database
    - Update data if Rhythmextractor's confidence is better than what is in DB
    - Add "delete data" button to GUI. Pressing it deletes the current song's (incorrect) data from DB.
- Fix running the program on Wayland
    - fix with Qt6 update when qtwayland should be in a better shape.
- Do something to gui.h/cpp. It's too big and messy.